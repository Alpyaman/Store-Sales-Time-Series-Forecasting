{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b99fd50",
   "metadata": {},
   "source": [
    "# Store Sales Time Series Forecasting - Debug Notebook\n",
    "\n",
    "This notebook debugs and fixes the issue where all predictions are coming out as $0.00 in our time series forecasting model for Favorita store sales.\n",
    "\n",
    "## Problem Analysis\n",
    "- Model is training successfully (RMSLE: 0.55333)\n",
    "- Predictions shape is correct (16, 1782)\n",
    "- But all final predictions are $0.00\n",
    "\n",
    "## Goals\n",
    "1. Debug the prediction-to-submission pipeline\n",
    "2. Fix the data merging issues\n",
    "3. Create proper submission format\n",
    "4. Validate the final predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4a58ca",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preparation\n",
    "\n",
    "Load the necessary libraries and data files for debugging the prediction pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202cd02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries loaded successfully!\n",
      "✓ Saved model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded successfully!\")\n",
    "\n",
    "# Load the saved model if it exists\n",
    "try:\n",
    "    model = joblib.load('time_series_model.pkl')\n",
    "    print(\"✓ Saved model loaded successfully\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ No saved model found. Need to run main.py first.\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29c79334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Submission file loaded: 28512 rows\n",
      "Sales statistics:\n",
      "  Min: $0.00\n",
      "  Max: $16574.79\n",
      "  Mean: $493.50\n",
      "  Unique values: 27356\n",
      "\n",
      "First 10 rows:\n",
      "        id        sales\n",
      "0  3000888     4.618296\n",
      "1  3000889     0.000000\n",
      "2  3000890     3.642586\n",
      "3  3000891  2435.995838\n",
      "4  3000892     0.348912\n",
      "5  3000893   466.477860\n",
      "6  3000894    16.137880\n",
      "7  3000895   837.301114\n",
      "8  3000896   885.084859\n",
      "9  3000897   147.604287\n"
     ]
    }
   ],
   "source": [
    "# Load the problematic submission file\n",
    "try:\n",
    "    submission_zero = pd.read_csv('submission_notebook_method.csv')\n",
    "    print(f\"✓ Submission file loaded: {len(submission_zero)} rows\")\n",
    "    print(\"Sales statistics:\")\n",
    "    print(f\"  Min: ${submission_zero['sales'].min():.2f}\")\n",
    "    print(f\"  Max: ${submission_zero['sales'].max():.2f}\")\n",
    "    print(f\"  Mean: ${submission_zero['sales'].mean():.2f}\")\n",
    "    print(f\"  Unique values: {submission_zero['sales'].nunique()}\")\n",
    "    \n",
    "    # Show first few rows\n",
    "    print(\"\\nFirst 10 rows:\")\n",
    "    print(submission_zero.head(10))\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"❌ No submission file found. Need to run main.py first.\")\n",
    "    submission_zero = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a66abe78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LOADING DATA ===\n",
      "Training data shape: (3000888, 1)\n",
      "Training period: 2013-01-01 to 2017-08-15\n",
      "Test data shape: (28512, 5)\n",
      "Test period: 2017-08-16 to 2017-08-31\n",
      "Test columns: ['id', 'date', 'store_nbr', 'family', 'onpromotion']\n",
      "\n",
      "Test data sample:\n",
      "        id        date  store_nbr      family  onpromotion\n",
      "0  3000888  2017-08-16          1  AUTOMOTIVE            0\n",
      "1  3000889  2017-08-16          1   BABY CARE            0\n",
      "2  3000890  2017-08-16          1      BEAUTY            2\n",
      "3  3000891  2017-08-16          1   BEVERAGES           20\n",
      "4  3000892  2017-08-16          1       BOOKS            0\n",
      "Training data shape: (3000888, 1)\n",
      "Training period: 2013-01-01 to 2017-08-15\n",
      "Test data shape: (28512, 5)\n",
      "Test period: 2017-08-16 to 2017-08-31\n",
      "Test columns: ['id', 'date', 'store_nbr', 'family', 'onpromotion']\n",
      "\n",
      "Test data sample:\n",
      "        id        date  store_nbr      family  onpromotion\n",
      "0  3000888  2017-08-16          1  AUTOMOTIVE            0\n",
      "1  3000889  2017-08-16          1   BABY CARE            0\n",
      "2  3000890  2017-08-16          1      BEAUTY            2\n",
      "3  3000891  2017-08-16          1   BEVERAGES           20\n",
      "4  3000892  2017-08-16          1       BOOKS            0\n"
     ]
    }
   ],
   "source": [
    "# Load the original data to understand structure\n",
    "print(\"=== LOADING DATA ===\")\n",
    "\n",
    "# Load training data\n",
    "train = pd.read_csv('train.csv', \n",
    "                   usecols=['store_nbr', 'family', 'date', 'sales'],\n",
    "                   dtype={'store_nbr': 'category', 'family': 'category'},\n",
    "                   parse_dates=['date'])\n",
    "train['date'] = train.date.dt.to_period('D')\n",
    "train = train.set_index(['date', 'family', 'store_nbr']).sort_index()\n",
    "\n",
    "print(f\"Training data shape: {train.shape}\")\n",
    "print(f\"Training period: {train.index.get_level_values('date').min()} to {train.index.get_level_values('date').max()}\")\n",
    "\n",
    "# Load test data\n",
    "test_orig = pd.read_csv('test.csv')\n",
    "test_orig['date'] = pd.to_datetime(test_orig['date']).dt.to_period('D')\n",
    "\n",
    "print(f\"Test data shape: {test_orig.shape}\")\n",
    "print(f\"Test period: {test_orig['date'].min()} to {test_orig['date'].max()}\")\n",
    "print(f\"Test columns: {test_orig.columns.tolist()}\")\n",
    "\n",
    "# Show sample of test data\n",
    "print(\"\\nTest data sample:\")\n",
    "print(test_orig.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3ab97a",
   "metadata": {},
   "source": [
    "## 2. Analyze the Wide Format Structure\n",
    "\n",
    "The model was trained on wide format data where each column represents a store-family combination. Let's examine this structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "926d3a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== WIDE FORMAT ANALYSIS ===\n",
      "Wide format shape: (1684, 1782)\n",
      "Columns (first 10): [('AUTOMOTIVE', '1'), ('AUTOMOTIVE', '10'), ('AUTOMOTIVE', '11'), ('AUTOMOTIVE', '12'), ('AUTOMOTIVE', '13'), ('AUTOMOTIVE', '14'), ('AUTOMOTIVE', '15'), ('AUTOMOTIVE', '16'), ('AUTOMOTIVE', '17'), ('AUTOMOTIVE', '18')]\n",
      "Column structure: <class 'pandas.core.indexes.multi.MultiIndex'>\n",
      "\n",
      "MultiIndex levels: 2\n",
      "Level 0 (families): CategoricalIndex(['AUTOMOTIVE', 'BABY CARE', 'BEAUTY', 'BEVERAGES', 'BOOKS',\n",
      "                  'BREAD/BAKERY', 'CELEBRATION', 'CLEANING', 'DAIRY', 'DELI',\n",
      "                  'EGGS', 'FROZEN FOODS', 'GROCERY I', 'GROCERY II',\n",
      "                  'HARDWARE', 'HOME AND KITCHEN I', 'HOME AND KITCHEN II',\n",
      "                  'HOME APPLIANCES', 'HOME CARE', 'LADIESWEAR',\n",
      "                  'LAWN AND GARDEN', 'LINGERIE', 'LIQUOR,WINE,BEER',\n",
      "                  'MAGAZINES', 'MEATS', 'PERSONAL CARE', 'PET SUPPLIES',\n",
      "                  'PLAYERS AND ELECTRONICS', 'POULTRY', 'PREPARED FOODS',\n",
      "                  'PRODUCE', 'SCHOOL AND OFFICE SUPPLIES', 'SEAFOOD'],\n",
      "                 categories=['AUTOMOTIVE', 'BABY CARE', 'BEAUTY', 'BEVERAGES', ..., 'PREPARED FOODS', 'PRODUCE', 'SCHOOL AND OFFICE SUPPLIES', 'SEAFOOD'], ordered=False, dtype='category', name='family')\n",
      "Level 1 (stores): CategoricalIndex(['1', '10', '11', '12', '13', '14', '15', '16', '17', '18'], categories=['1', '10', '11', '12', ..., '6', '7', '8', '9'], ordered=False, dtype='category', name='store_nbr')\n",
      "\n",
      "Wide format sample (last 5 dates, first 5 columns):\n",
      "family     AUTOMOTIVE                      \n",
      "store_nbr           1   10    11    12   13\n",
      "date                                       \n",
      "2017-08-11        1.0  2.0  10.0   6.0  6.0\n",
      "2017-08-12        6.0  2.0  11.0   8.0  9.0\n",
      "2017-08-13        1.0  0.0   6.0  12.0  2.0\n",
      "2017-08-14        1.0  1.0   2.0   6.0  2.0\n",
      "2017-08-15        4.0  4.0   6.0   2.0  4.0\n",
      "\n",
      "Wide format data type: float64\n",
      "Wide format stats for first column:\n",
      "count    1684.000000\n",
      "mean        3.251188\n",
      "std         2.759605\n",
      "min         0.000000\n",
      "25%         1.000000\n",
      "50%         3.000000\n",
      "75%         5.000000\n",
      "max        19.000000\n",
      "Name: (AUTOMOTIVE, 1), dtype: float64\n",
      "\n",
      "=== CREATING MOCK PREDICTIONS ===\n",
      "Mock predictions shape: (16, 1782)\n",
      "Mock predictions stats:\n",
      "  Min: 10.00\n",
      "  Max: 100.00\n",
      "  Mean: 54.94\n",
      "\n",
      "Mock predictions sample:\n",
      "family     AUTOMOTIVE                      \n",
      "store_nbr           1         10         11\n",
      "2017-08-16  95.556513  43.390755  25.027545\n",
      "2017-08-17  90.710532  98.579531  46.220241\n",
      "2017-08-18  45.993778  90.765700  16.470088\n"
     ]
    }
   ],
   "source": [
    "# Analyze the wide format structure\n",
    "print(\"=== WIDE FORMAT ANALYSIS ===\")\n",
    "print(f\"Wide format shape: {y_train_wide.shape}\")\n",
    "print(f\"Columns (first 10): {y_train_wide.columns.tolist()[:10]}\")\n",
    "print(f\"Column structure: {type(y_train_wide.columns)}\")\n",
    "\n",
    "if hasattr(y_train_wide.columns, 'nlevels'):\n",
    "    print(f\"\\nMultiIndex levels: {y_train_wide.columns.nlevels}\")\n",
    "    print(f\"Level 0 (families): {y_train_wide.columns.get_level_values(0).unique()}\")\n",
    "    print(f\"Level 1 (stores): {y_train_wide.columns.get_level_values(1).unique()[:10]}\")\n",
    "else:\n",
    "    print(f\"Regular columns: {y_train_wide.columns[:10]}\")\n",
    "\n",
    "# Show a sample of the wide format data\n",
    "print(\"\\nWide format sample (last 5 dates, first 5 columns):\")\n",
    "print(y_train_wide.iloc[-5:, :5])\n",
    "print(f\"\\nWide format data type: {y_train_wide.dtypes.iloc[0]}\")\n",
    "print(f\"Wide format stats for first column:\")\n",
    "print(y_train_wide.iloc[:, 0].describe())\n",
    "\n",
    "# Create mock predictions with same structure as training\n",
    "print(\"\\n=== CREATING MOCK PREDICTIONS ===\")\n",
    "mock_predictions = pd.DataFrame(\n",
    "    np.random.uniform(10, 100, size=(16, 1782)),  # Random values between 10-100\n",
    "    index=pd.period_range('2017-08-16', periods=16, freq='D'),\n",
    "    columns=y_train_wide.columns\n",
    ")\n",
    "\n",
    "print(f\"Mock predictions shape: {mock_predictions.shape}\")\n",
    "print(f\"Mock predictions stats:\")\n",
    "print(f\"  Min: {mock_predictions.min().min():.2f}\")\n",
    "print(f\"  Max: {mock_predictions.max().max():.2f}\")\n",
    "print(f\"  Mean: {mock_predictions.mean().mean():.2f}\")\n",
    "print(f\"\\nMock predictions sample:\")\n",
    "print(mock_predictions.iloc[:3, :3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befadf7d",
   "metadata": {},
   "source": [
    "## 3. Simulate Prediction Process\n",
    "\n",
    "Let's simulate the prediction process step by step to identify where the zeros are coming from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bb71e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTING PREDICTION PIPELINE ===\n",
      "Mock predictions shape: (16, 1782)\n",
      "Mock prediction range: 10.00 - 99.99\n",
      "Mock prediction mean: 54.99\n",
      "Test dates: PeriodIndex(['2017-08-16', '2017-08-17', '2017-08-18', '2017-08-19',\n",
      "             '2017-08-20'],\n",
      "            dtype='period[D]') ... PeriodIndex(['2017-08-30', '2017-08-31'], dtype='period[D]')\n",
      "Prediction DataFrame shape: (16, 1782)\n",
      "Prediction DataFrame sample:\n",
      "family     AUTOMOTIVE                      \n",
      "store_nbr           1         10         11\n",
      "2017-08-16  43.708611  95.564288  75.879455\n",
      "2017-08-17  51.532972  67.348133  69.341853\n",
      "2017-08-18  51.258828  75.250547  61.685882\n"
     ]
    }
   ],
   "source": [
    "# Create mock predictions to test the pipeline\n",
    "print(\"=== TESTING PREDICTION PIPELINE ===\")\n",
    "\n",
    "# Create fake predictions with known non-zero values\n",
    "n_test_periods = 16  # From the output\n",
    "n_columns = 1782     # From the output\n",
    "\n",
    "# Create mock predictions with realistic values\n",
    "np.random.seed(42)\n",
    "mock_predictions = np.random.uniform(10, 100, size=(n_test_periods, n_columns))\n",
    "\n",
    "print(f\"Mock predictions shape: {mock_predictions.shape}\")\n",
    "print(f\"Mock prediction range: {mock_predictions.min():.2f} - {mock_predictions.max():.2f}\")\n",
    "print(f\"Mock prediction mean: {mock_predictions.mean():.2f}\")\n",
    "\n",
    "# Create test dates (same as in the model)\n",
    "test_dates = pd.period_range('2017-08-16', '2017-08-31', freq='D')\n",
    "print(f\"Test dates: {test_dates[:5]} ... {test_dates[-2:]}\")\n",
    "\n",
    "# Create prediction DataFrame using the same column structure\n",
    "pred_df = pd.DataFrame(mock_predictions, \n",
    "                      index=test_dates,\n",
    "                      columns=y_train_wide.columns)\n",
    "\n",
    "print(f\"Prediction DataFrame shape: {pred_df.shape}\")\n",
    "print(\"Prediction DataFrame sample:\")\n",
    "print(pred_df.iloc[:3, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db7fcea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTING STACKING PROCESS ===\n",
      "Stacked shape: (28512, 4)\n",
      "Stacked columns: ['level_0', 'family', 'store_nbr', 'sales']\n",
      "Stacked sample:\n",
      "      level_0      family store_nbr      sales\n",
      "0  2017-08-16  AUTOMOTIVE         1  43.708611\n",
      "1  2017-08-16  AUTOMOTIVE        10  95.564288\n",
      "2  2017-08-16  AUTOMOTIVE        11  75.879455\n",
      "3  2017-08-16  AUTOMOTIVE        12  63.879264\n",
      "4  2017-08-16  AUTOMOTIVE        13  24.041678\n",
      "5  2017-08-16  AUTOMOTIVE        14  24.039507\n",
      "6  2017-08-16  AUTOMOTIVE        15  15.227525\n",
      "7  2017-08-16  AUTOMOTIVE        16  87.955853\n",
      "8  2017-08-16  AUTOMOTIVE        17  64.100351\n",
      "9  2017-08-16  AUTOMOTIVE        18  73.726532\n",
      "\n",
      "Stacked sales statistics:\n",
      "Min: 10.00\n",
      "Max: 99.99\n",
      "Mean: 54.99\n",
      "Non-zero count: 28512\n",
      "\n",
      "Column data types:\n",
      "level_0      period[D]\n",
      "family        category\n",
      "store_nbr     category\n",
      "sales          float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Test the stacking process (this is where the problem likely occurs)\n",
    "print(\"=== TESTING STACKING PROCESS ===\")\n",
    "\n",
    "# Stack the predictions back to long format\n",
    "pred_stacked = pred_df.stack(['family', 'store_nbr']).to_frame()\n",
    "pred_stacked.columns = ['sales']\n",
    "pred_stacked = pred_stacked.reset_index()\n",
    "\n",
    "print(f\"Stacked shape: {pred_stacked.shape}\")\n",
    "print(f\"Stacked columns: {pred_stacked.columns.tolist()}\")\n",
    "print(\"Stacked sample:\")\n",
    "print(pred_stacked.head(10))\n",
    "\n",
    "# Check if we have non-zero values\n",
    "print(\"\\nStacked sales statistics:\")\n",
    "print(f\"Min: {pred_stacked['sales'].min():.2f}\")\n",
    "print(f\"Max: {pred_stacked['sales'].max():.2f}\")\n",
    "print(f\"Mean: {pred_stacked['sales'].mean():.2f}\")\n",
    "print(f\"Non-zero count: {(pred_stacked['sales'] > 0).sum()}\")\n",
    "\n",
    "# Check the column names after stacking\n",
    "print(\"\\nColumn data types:\")\n",
    "print(pred_stacked.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b49a112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TESTING MERGE PROCESS ===\n",
      "Fixed stacked columns: ['date', 'family', 'store_nbr', 'sales']\n",
      "Fixed stacked sample:\n",
      "         date      family store_nbr      sales\n",
      "0  2017-08-16  AUTOMOTIVE         1  43.708611\n",
      "1  2017-08-16  AUTOMOTIVE        10  95.564288\n",
      "2  2017-08-16  AUTOMOTIVE        11  75.879455\n",
      "3  2017-08-16  AUTOMOTIVE        12  63.879264\n",
      "4  2017-08-16  AUTOMOTIVE        13  24.041678\n",
      "\n",
      "Test data columns: ['id', 'date', 'store_nbr', 'family', 'onpromotion']\n",
      "Test data sample:\n",
      "        id        date  store_nbr      family\n",
      "0  3000888  2017-08-16          1  AUTOMOTIVE\n",
      "1  3000889  2017-08-16          1   BABY CARE\n",
      "2  3000890  2017-08-16          1      BEAUTY\n",
      "3  3000891  2017-08-16          1   BEVERAGES\n",
      "4  3000892  2017-08-16          1       BOOKS\n",
      "\n",
      "Merge successful!\n",
      "Merged shape: (28512, 6)\n",
      "Merged sales stats:\n",
      "  Min: nan\n",
      "  Max: nan\n",
      "  Mean: nan\n",
      "  Non-null count: 0\n",
      "\n",
      "Merged data sample:\n",
      "        id        date        family store_nbr  sales\n",
      "0  3000888  2017-08-16    AUTOMOTIVE         1    NaN\n",
      "1  3000889  2017-08-16     BABY CARE         1    NaN\n",
      "2  3000890  2017-08-16        BEAUTY         1    NaN\n",
      "3  3000891  2017-08-16     BEVERAGES         1    NaN\n",
      "4  3000892  2017-08-16         BOOKS         1    NaN\n",
      "5  3000893  2017-08-16  BREAD/BAKERY         1    NaN\n",
      "6  3000894  2017-08-16   CELEBRATION         1    NaN\n",
      "7  3000895  2017-08-16      CLEANING         1    NaN\n",
      "8  3000896  2017-08-16         DAIRY         1    NaN\n",
      "9  3000897  2017-08-16          DELI         1    NaN\n"
     ]
    }
   ],
   "source": [
    "# Test merging with test data\n",
    "print(\"=== TESTING MERGE PROCESS ===\")\n",
    "\n",
    "# The issue is in the column name after stacking - it should be 'date' not 'level_0'\n",
    "# Let's fix the stacked data column names\n",
    "pred_stacked_fixed = pred_stacked.copy()\n",
    "\n",
    "# The first column after reset_index should be the date\n",
    "if 'level_0' in pred_stacked_fixed.columns:\n",
    "    pred_stacked_fixed = pred_stacked_fixed.rename(columns={'level_0': 'date'})\n",
    "\n",
    "print(f\"Fixed stacked columns: {pred_stacked_fixed.columns.tolist()}\")\n",
    "print(\"Fixed stacked sample:\")\n",
    "print(pred_stacked_fixed.head())\n",
    "\n",
    "# Now test the merge\n",
    "print(f\"\\nTest data columns: {test_orig.columns.tolist()}\")\n",
    "print(\"Test data sample:\")\n",
    "print(test_orig[['id', 'date', 'store_nbr', 'family']].head())\n",
    "\n",
    "# Try merging on the correct columns\n",
    "try:\n",
    "    merged = test_orig.merge(\n",
    "        pred_stacked_fixed[['date', 'family', 'store_nbr', 'sales']], \n",
    "        on=['date', 'family', 'store_nbr'], \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    print(\"\\nMerge successful!\")\n",
    "    print(f\"Merged shape: {merged.shape}\")\n",
    "    print(\"Merged sales stats:\")\n",
    "    print(f\"  Min: {merged['sales'].min():.2f}\")\n",
    "    print(f\"  Max: {merged['sales'].max():.2f}\")\n",
    "    print(f\"  Mean: {merged['sales'].mean():.2f}\")\n",
    "    print(f\"  Non-null count: {merged['sales'].notna().sum()}\")\n",
    "    \n",
    "    # Show sample of merged data\n",
    "    print(\"\\nMerged data sample:\")\n",
    "    print(merged[['id', 'date', 'family', 'store_nbr', 'sales']].head(10))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Merge failed: {e}\")\n",
    "    print(\"Trying to debug data types...\")\n",
    "    print(f\"Test date type: {test_orig['date'].dtype}\")\n",
    "    print(f\"Pred date type: {pred_stacked_fixed['date'].dtype}\")\n",
    "    print(f\"Test family type: {test_orig['family'].dtype}\")\n",
    "    print(f\"Pred family type: {pred_stacked_fixed['family'].dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36fd6b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEBUGGING MERGE FAILURE ===\n",
      "Data type comparison:\n",
      "Test date type: period[D]\n",
      "Pred date type: period[D]\n",
      "Test store_nbr type: int64\n",
      "Pred store_nbr type: category\n",
      "Test family type: object\n",
      "Pred family type: category\n",
      "\n",
      "Sample values comparison:\n",
      "Test data first 5 unique combinations:\n",
      "         date      family  store_nbr\n",
      "0  2017-08-16  AUTOMOTIVE          1\n",
      "1  2017-08-16   BABY CARE          1\n",
      "2  2017-08-16      BEAUTY          1\n",
      "3  2017-08-16   BEVERAGES          1\n",
      "4  2017-08-16       BOOKS          1\n",
      "\n",
      "Prediction data first 5 rows:\n",
      "         date      family store_nbr\n",
      "0  2017-08-16  AUTOMOTIVE         1\n",
      "1  2017-08-16  AUTOMOTIVE        10\n",
      "2  2017-08-16  AUTOMOTIVE        11\n",
      "3  2017-08-16  AUTOMOTIVE        12\n",
      "4  2017-08-16  AUTOMOTIVE        13\n",
      "\n",
      "Checking if date formats match:\n",
      "Test date samples: [Period('2017-08-16', 'D'), Period('2017-08-16', 'D'), Period('2017-08-16', 'D'), Period('2017-08-16', 'D'), Period('2017-08-16', 'D')]\n",
      "Pred date samples: [Period('2017-08-16', 'D'), Period('2017-08-16', 'D'), Period('2017-08-16', 'D'), Period('2017-08-16', 'D'), Period('2017-08-16', 'D')]\n",
      "\n",
      "After conversion:\n",
      "Pred date type: datetime64[ns]\n",
      "Pred store_nbr type: int64\n",
      "\n",
      "Fixed merge stats:\n",
      "Merged shape: (28512, 6)\n",
      "Non-null sales: 0\n",
      "Sales range: nan - nan\n",
      "\n",
      "Fixed merged sample:\n",
      "        id        date        family  store_nbr  sales\n",
      "0  3000888  2017-08-16    AUTOMOTIVE          1    NaN\n",
      "1  3000889  2017-08-16     BABY CARE          1    NaN\n",
      "2  3000890  2017-08-16        BEAUTY          1    NaN\n",
      "3  3000891  2017-08-16     BEVERAGES          1    NaN\n",
      "4  3000892  2017-08-16         BOOKS          1    NaN\n",
      "5  3000893  2017-08-16  BREAD/BAKERY          1    NaN\n",
      "6  3000894  2017-08-16   CELEBRATION          1    NaN\n",
      "7  3000895  2017-08-16      CLEANING          1    NaN\n",
      "8  3000896  2017-08-16         DAIRY          1    NaN\n",
      "9  3000897  2017-08-16          DELI          1    NaN\n",
      "\n",
      "Fixed merge stats:\n",
      "Merged shape: (28512, 6)\n",
      "Non-null sales: 0\n",
      "Sales range: nan - nan\n",
      "\n",
      "Fixed merged sample:\n",
      "        id        date        family  store_nbr  sales\n",
      "0  3000888  2017-08-16    AUTOMOTIVE          1    NaN\n",
      "1  3000889  2017-08-16     BABY CARE          1    NaN\n",
      "2  3000890  2017-08-16        BEAUTY          1    NaN\n",
      "3  3000891  2017-08-16     BEVERAGES          1    NaN\n",
      "4  3000892  2017-08-16         BOOKS          1    NaN\n",
      "5  3000893  2017-08-16  BREAD/BAKERY          1    NaN\n",
      "6  3000894  2017-08-16   CELEBRATION          1    NaN\n",
      "7  3000895  2017-08-16      CLEANING          1    NaN\n",
      "8  3000896  2017-08-16         DAIRY          1    NaN\n",
      "9  3000897  2017-08-16          DELI          1    NaN\n"
     ]
    }
   ],
   "source": [
    "# Debug the merge failure\n",
    "print(\"=== DEBUGGING MERGE FAILURE ===\")\n",
    "\n",
    "print(\"Data type comparison:\")\n",
    "print(f\"Test date type: {test_orig['date'].dtype}\")\n",
    "print(f\"Pred date type: {pred_stacked_fixed['date'].dtype}\")\n",
    "print(f\"Test store_nbr type: {test_orig['store_nbr'].dtype}\")\n",
    "print(f\"Pred store_nbr type: {pred_stacked_fixed['store_nbr'].dtype}\")\n",
    "print(f\"Test family type: {test_orig['family'].dtype}\")\n",
    "print(f\"Pred family type: {pred_stacked_fixed['family'].dtype}\")\n",
    "\n",
    "print(\"\\nSample values comparison:\")\n",
    "print(\"Test data first 5 unique combinations:\")\n",
    "test_sample = test_orig[['date', 'family', 'store_nbr']].head()\n",
    "print(test_sample)\n",
    "\n",
    "print(\"\\nPrediction data first 5 rows:\")\n",
    "pred_sample = pred_stacked_fixed[['date', 'family', 'store_nbr']].head()\n",
    "print(pred_sample)\n",
    "\n",
    "print(\"\\nChecking if date formats match:\")\n",
    "print(f\"Test date samples: {test_orig['date'].head().tolist()}\")\n",
    "print(f\"Pred date samples: {pred_stacked_fixed['date'].head().tolist()}\")\n",
    "\n",
    "# Try to fix data types for merge\n",
    "pred_stacked_for_merge = pred_stacked_fixed.copy()\n",
    "\n",
    "# Convert Period to datetime if needed\n",
    "if pred_stacked_for_merge['date'].dtype.name.startswith('period'):\n",
    "    pred_stacked_for_merge['date'] = pred_stacked_for_merge['date'].dt.to_timestamp().dt.date\n",
    "    pred_stacked_for_merge['date'] = pd.to_datetime(pred_stacked_for_merge['date'])\n",
    "\n",
    "# Convert store_nbr to integer if needed  \n",
    "pred_stacked_for_merge['store_nbr'] = pred_stacked_for_merge['store_nbr'].astype(str).astype(int)\n",
    "\n",
    "print(f\"\\nAfter conversion:\")\n",
    "print(f\"Pred date type: {pred_stacked_for_merge['date'].dtype}\")\n",
    "print(f\"Pred store_nbr type: {pred_stacked_for_merge['store_nbr'].dtype}\")\n",
    "\n",
    "# Test merge again\n",
    "merged_fixed = test_orig.merge(\n",
    "    pred_stacked_for_merge[['date', 'family', 'store_nbr', 'sales']], \n",
    "    on=['date', 'family', 'store_nbr'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\nFixed merge stats:\")\n",
    "print(f\"Merged shape: {merged_fixed.shape}\")\n",
    "print(f\"Non-null sales: {merged_fixed['sales'].notna().sum()}\")\n",
    "print(f\"Sales range: {merged_fixed['sales'].min():.2f} - {merged_fixed['sales'].max():.2f}\")\n",
    "print(f\"\\nFixed merged sample:\")\n",
    "print(merged_fixed[['id', 'date', 'family', 'store_nbr', 'sales']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "136625aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DETAILED KEY MATCHING ===\n",
      "Creating merge keys:\n",
      "Test unique keys: 28512\n",
      "Pred unique keys: 28512\n",
      "\n",
      "First 10 test keys:\n",
      "        date        family  store_nbr\n",
      "0 2017-08-16    AUTOMOTIVE          1\n",
      "1 2017-08-16     BABY CARE          1\n",
      "2 2017-08-16        BEAUTY          1\n",
      "3 2017-08-16     BEVERAGES          1\n",
      "4 2017-08-16         BOOKS          1\n",
      "5 2017-08-16  BREAD/BAKERY          1\n",
      "6 2017-08-16   CELEBRATION          1\n",
      "7 2017-08-16      CLEANING          1\n",
      "8 2017-08-16         DAIRY          1\n",
      "9 2017-08-16          DELI          1\n",
      "\n",
      "First 10 pred keys:\n",
      "        date      family  store_nbr\n",
      "0 2017-08-16  AUTOMOTIVE          1\n",
      "1 2017-08-16  AUTOMOTIVE         10\n",
      "2 2017-08-16  AUTOMOTIVE         11\n",
      "3 2017-08-16  AUTOMOTIVE         12\n",
      "4 2017-08-16  AUTOMOTIVE         13\n",
      "5 2017-08-16  AUTOMOTIVE         14\n",
      "6 2017-08-16  AUTOMOTIVE         15\n",
      "7 2017-08-16  AUTOMOTIVE         16\n",
      "8 2017-08-16  AUTOMOTIVE         17\n",
      "9 2017-08-16  AUTOMOTIVE         18\n",
      "\n",
      "Testing specific matches:\n",
      "Looking for ('2017-08-16', 'AUTOMOTIVE', 1)\n",
      "Found 1 matches in predictions:\n",
      "        date      family  store_nbr      sales\n",
      "0 2017-08-16  AUTOMOTIVE          1  43.708611\n",
      "\n",
      "Total matching keys: 28512\n",
      "Matching keys sample:\n",
      "        date      family  store_nbr\n",
      "0 2017-08-16  AUTOMOTIVE          1\n",
      "1 2017-08-16   BABY CARE          1\n",
      "2 2017-08-16      BEAUTY          1\n",
      "3 2017-08-16   BEVERAGES          1\n",
      "4 2017-08-16       BOOKS          1\n"
     ]
    }
   ],
   "source": [
    "# Check key matching in detail\n",
    "print(\"=== DETAILED KEY MATCHING ===\")\n",
    "\n",
    "# Convert test date to datetime for comparison\n",
    "test_for_comparison = test_orig.copy()\n",
    "test_for_comparison['date'] = test_for_comparison['date'].dt.to_timestamp().dt.date\n",
    "test_for_comparison['date'] = pd.to_datetime(test_for_comparison['date'])\n",
    "\n",
    "print(\"Creating merge keys:\")\n",
    "test_keys = test_for_comparison[['date', 'family', 'store_nbr']].drop_duplicates()\n",
    "pred_keys = pred_stacked_for_merge[['date', 'family', 'store_nbr']].drop_duplicates()\n",
    "\n",
    "print(f\"Test unique keys: {len(test_keys)}\")\n",
    "print(f\"Pred unique keys: {len(pred_keys)}\")\n",
    "\n",
    "print(f\"\\nFirst 10 test keys:\")\n",
    "print(test_keys.head(10))\n",
    "\n",
    "print(f\"\\nFirst 10 pred keys:\")\n",
    "print(pred_keys.head(10))\n",
    "\n",
    "# Check for exact matches\n",
    "print(\"\\nTesting specific matches:\")\n",
    "test_key1 = ('2017-08-16', 'AUTOMOTIVE', 1)\n",
    "pred_match = pred_stacked_for_merge[\n",
    "    (pred_stacked_for_merge['date'] == pd.to_datetime('2017-08-16')) &\n",
    "    (pred_stacked_for_merge['family'] == 'AUTOMOTIVE') &\n",
    "    (pred_stacked_for_merge['store_nbr'] == 1)\n",
    "]\n",
    "print(f\"Looking for {test_key1}\")\n",
    "print(f\"Found {len(pred_match)} matches in predictions:\")\n",
    "if len(pred_match) > 0:\n",
    "    print(pred_match[['date', 'family', 'store_nbr', 'sales']])\n",
    "\n",
    "# Check if any keys match at all\n",
    "merged_keys = test_keys.merge(pred_keys, on=['date', 'family', 'store_nbr'], how='inner')\n",
    "print(f\"\\nTotal matching keys: {len(merged_keys)}\")\n",
    "\n",
    "if len(merged_keys) == 0:\n",
    "    print(\"NO KEYS MATCH! Let's debug further...\")\n",
    "    \n",
    "    # Check each column individually\n",
    "    test_dates = set(test_for_comparison['date'].unique())\n",
    "    pred_dates = set(pred_stacked_for_merge['date'].unique())\n",
    "    print(f\"Date overlap: {len(test_dates & pred_dates)} of {len(test_dates)} test dates\")\n",
    "    print(f\"Test dates: {sorted(list(test_dates))[:5]}\")\n",
    "    print(f\"Pred dates: {sorted(list(pred_dates))[:5]}\")\n",
    "    \n",
    "    test_families = set(test_for_comparison['family'].unique())\n",
    "    pred_families = set(pred_stacked_for_merge['family'].unique())\n",
    "    print(f\"Family overlap: {len(test_families & pred_families)} of {len(test_families)} test families\")\n",
    "    \n",
    "    test_stores = set(test_for_comparison['store_nbr'].unique())\n",
    "    pred_stores = set(pred_stacked_for_merge['store_nbr'].unique())\n",
    "    print(f\"Store overlap: {len(test_stores & pred_stores)} of {len(test_stores)} test stores\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Matching keys sample:\")\n",
    "    print(merged_keys.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
